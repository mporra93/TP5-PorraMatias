{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP5\n",
    "## CEIA - Cohorte 7 - 2022\n",
    "## Matias Porra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Implementar el detector de fondo naive usando la mediana como estimador. El algoritmo debe recibir el parámetro N (cantidad de 7 frames utilizados para la estimación) y el intervalo de tiempo para recalcular el fondo.\n",
    "##### 2. Se deben generar las mascaras de foreground y aplicarlas a los frames para segmentar los objetos en movimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (16.0, 16.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Naive:\n",
    "    \n",
    "    def __init__(self, n_frames, time_interval, filename):\n",
    "        self.capture = cv.VideoCapture(filename)        \n",
    "        if not self.capture.isOpened:\n",
    "            print('Falla al abrir el archivo: ' + filename)\n",
    "            exit(0)\n",
    "        \n",
    "        self.n_frames = n_frames\n",
    "        self.fps = self.capture.get(cv.CAP_PROP_FPS)\n",
    "        self.interval = time_interval * self.fps \n",
    "        self.frame_width = int(self.capture.get(3))\n",
    "        self.frame_height = int(self.capture.get(4))\n",
    "        self.output_path = \"./output/\" \n",
    "        self.setBackground()\n",
    "    \n",
    "    def get_Background(self):\n",
    "        frame_n = int(self.capture.get(cv.CAP_PROP_FRAME_COUNT)) * np.random.uniform(size=n_frames)\n",
    "        frames = []\n",
    "        for frame_num in frame_n:\n",
    "            self.capture.set(cv.CAP_PROP_POS_FRAMES, frame_num)\n",
    "            ret, frame = self.capture.read()\n",
    "            frames.append(frame)\n",
    "\n",
    "        background = np.median(frames, axis=0).astype(dtype=np.uint8)\n",
    "        return background\n",
    "    \n",
    "    def setBackground(self, frame_queue=None):\n",
    "        if frame_queue:\n",
    "            frame_n = len(frame_queue) * np.random.uniform(size=self.n_frames)\n",
    "            frame_n = frame_n.astype(dtype=np.uint8)\n",
    "            bg_frames = np.array(frame_queue)[frame_n]\n",
    "            self.background = np.median(bg_frames, axis=0).astype(dtype=np.uint8)\n",
    "        else:\n",
    "            self.background = self.get_Background()\n",
    "        \n",
    "    def getBackground(self):\n",
    "        return self.background        \n",
    "        \n",
    "    def add(self):\n",
    "        fourcc = cv.VideoWriter_fourcc(*'mp4v')\n",
    "        output_filename = \"output_nbs.mp4\"\n",
    "        output = cv.VideoWriter(self.output_path + \"/\" + output_filename,\n",
    "                               fourcc,\n",
    "                               self.fps,\n",
    "                               (self.frame_width, self.frame_height),\n",
    "                               False)\n",
    "        # Reseteamos los frames\n",
    "        self.capture.set(cv.CAP_PROP_POS_FRAMES, 0)\n",
    "        start = time.time()\n",
    "        gray_background = cv.cvtColor(self.background, cv.COLOR_BGR2GRAY)\n",
    "        frame_queue = []\n",
    "        ret, frame = self.capture.read()\n",
    "        while ret:\n",
    "            frame_queue.append(frame)\n",
    "            # recalculo el fondo\n",
    "            if len(frame_queue) % self.interval == 0:\n",
    "                self.setBackground(frame_queue)\n",
    "                gray_background = cv.cvtColor(self.background, cv.COLOR_BGR2GRAY)\n",
    "                frame_queue = []\n",
    "            frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "            dframe = cv.absdiff(frame, gray_background)\n",
    "            th, dframe = cv.threshold(dframe, 30, 255, cv.THRESH_BINARY)\n",
    "            output.write(dframe)\n",
    "\n",
    "            ret, frame = self.capture.read()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_frames = 60\n",
    "time_interval = 20 # in seconds\n",
    "output_path = \"./output/\"\n",
    "FILENAME = 'videos/vtest.avi' \n",
    "\n",
    "nbs = Naive(n_frames=n_frames, time_interval=time_interval, filename=FILENAME)\n",
    "nbs.add()\n",
    "capture = cv.VideoCapture(output_path + \"output_nbs.mp4\")\n",
    "capture.set(cv.CAP_PROP_POS_FRAMES, 540)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Comparar con alguno de los métodos vistos en la practica basados en mezcla de gaussianas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MOG2:\n",
    "    \n",
    "    def __init__(self, filename):\n",
    "        self.capture = cv.VideoCapture(filename)    \n",
    "        if not self.capture.isOpened:\n",
    "            print('Falla al abrir el archivo: ' + filename)\n",
    "            exit(0)\n",
    "            \n",
    "        self.backSub = cv.createBackgroundSubtractorMOG2()\n",
    "        \n",
    "        self.fps = self.capture.get(cv.CAP_PROP_FPS)\n",
    "        self.frame_width = int(self.capture.get(3))\n",
    "        self.frame_height = int(self.capture.get(4))\n",
    "        self.output_path = \"./output/\"\n",
    "    \n",
    "    def add(self, output_filename=None):\n",
    "        fourcc = cv.VideoWriter_fourcc(*'mp4v')\n",
    "        output = cv.VideoWriter(self.output_path + \"/\" + output_filename,\n",
    "                               fourcc,\n",
    "                               self.fps,\n",
    "                               (self.frame_width, self.frame_height),\n",
    "                               False)\n",
    "\n",
    "        self.capture.set(cv.CAP_PROP_POS_FRAMES, 0)\n",
    "        start = time.time()      \n",
    "        ret, frame = self.capture.read()\n",
    "        while ret:\n",
    "            # Leemos un frame\n",
    "            if frame is None:\n",
    "                break\n",
    "            fgMask = self.backSub.apply(frame)\n",
    "            output.write(fgMask)\n",
    "            ret, frame = self.capture.read()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mog2 = MOG2(FILENAME)\n",
    "mog2.add(output_filename=\"mog2.mp4\")\n",
    "capture = cv.VideoCapture(output_path + \"/mog2.mp4\")\n",
    "capture.set(cv.CAP_PROP_POS_FRAMES, 540)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "##### Naive detecta mejor el fondo que MOG2, quiza con una erosion para eliminar el ruido de alrededor de los objetos MOG2 mejoraria"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 ('cv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49cc7f33b63d2a59a94cdd5905a9d69fd357a4127d48e5e12af1b13af86b584e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
